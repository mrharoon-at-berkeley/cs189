{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "40cfba38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4b67c8bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data set\n",
    "mnist_data = np.load(\"../data/mnist-data.npz\")\n",
    "spam_data = np.load(\"../data/spam-data.npz\")\n",
    "cifar10_data = np.load(\"../data/cifar10-data.npz\")\n",
    "\n",
    "data_files = [mnist_data, spam_data, cifar_data]\n",
    "\n",
    "# generate numpy.Generator\n",
    "rng = np.random.default_rng()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5721db91",
   "metadata": {},
   "source": [
    "# Q1. Shuffle and Partition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "9a009500",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "<numpy.lib.npyio.NpzFile object at 0x16a29a190>\n"
     ]
    },
    {
     "ename": "UnboundLocalError",
     "evalue": "cannot access local variable 'i' where it is not associated with a value",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[55], line 32\u001b[0m\n\u001b[1;32m     29\u001b[0m mnist_vset, spam_vset, cifar_vset \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;66;03m# Process each dataset using a list comprehension\u001b[39;00m\n\u001b[0;32m---> 32\u001b[0m validation_sets \u001b[38;5;241m=\u001b[39m \u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[43mshuffle_and_partition\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_samples\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdata_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_samples\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mzip\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdata_files\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_sample_sizes\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msets\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mvalidation_sets\u001b[49m\u001b[43m]\u001b[49m\n",
      "Cell \u001b[0;32mIn[55], line 32\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     29\u001b[0m mnist_vset, spam_vset, cifar_vset \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;66;03m# Process each dataset using a list comprehension\u001b[39;00m\n\u001b[0;32m---> 32\u001b[0m validation_sets \u001b[38;5;241m=\u001b[39m [\u001b[43m[\u001b[49m\u001b[43mshuffle_and_partition\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_samples\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdata_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_samples\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mzip\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdata_files\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_sample_sizes\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m sets \u001b[38;5;129;01min\u001b[39;00m validation_sets]\n",
      "Cell \u001b[0;32mIn[55], line 32\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     29\u001b[0m mnist_vset, spam_vset, cifar_vset \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;66;03m# Process each dataset using a list comprehension\u001b[39;00m\n\u001b[0;32m---> 32\u001b[0m validation_sets \u001b[38;5;241m=\u001b[39m [[\u001b[43mshuffle_and_partition\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_samples\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m data_file, val_samples \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(data_files, validation_sample_sizes)] \u001b[38;5;28;01mfor\u001b[39;00m sets \u001b[38;5;129;01min\u001b[39;00m validation_sets]\n",
      "Cell \u001b[0;32mIn[55], line 7\u001b[0m, in \u001b[0;36mshuffle_and_partition\u001b[0;34m(data_file, num_validation_samples)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mshuffle_and_partition\u001b[39m(data_file, num_validation_samples):\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;66;03m# Extract features and labels\u001b[39;00m\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28mprint\u001b[39m(data_file)\n\u001b[0;32m----> 7\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[43mi\u001b[49m)\n\u001b[1;32m      8\u001b[0m     i\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m      9\u001b[0m     X \u001b[38;5;241m=\u001b[39m data_file[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtraining_data\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[0;31mUnboundLocalError\u001b[0m: cannot access local variable 'i' where it is not associated with a value"
     ]
    }
   ],
   "source": [
    "def shuffle_and_partition(data_file, num_validation_samples):\n",
    "    # Extract features and labels\n",
    "    print(data_file)\n",
    "    X = data_file['training_data']\n",
    "    y = data_file['training_labels']\n",
    "\n",
    "    # Shuffle the data and labels together in a random order\n",
    "    indices = np.arange(X.shape[0])\n",
    "    np.random.shuffle(indices)\n",
    "    X_shuffled = X[indices]\n",
    "    y_shuffled = y[indices]\n",
    "\n",
    "    # Set aside validation samples\n",
    "    X_train = X_shuffled[:-num_validation_samples]\n",
    "    y_train = y_shuffled[:-num_validation_samples]\n",
    "    X_val = X_shuffled[-num_validation_samples:]\n",
    "    y_val = y_shuffled[-num_validation_samples:]\n",
    "\n",
    "    return X_train, y_train, X_val, y_val\n",
    "\n",
    "\n",
    "# Define the validation sample sizes\n",
    "validation_sample_sizes = [10000, int(0.2 * 5172), 5000]\n",
    "mnist_vset, spam_vset, cifar_vset = None, None, None\n",
    "\n",
    "# Process each dataset using a list comprehension\n",
    "validation_sets = [\n",
    "    [shuffle_and_partition(data_file, val_samples) for data_file, val_samples in zip(data_files, validation_sample_sizes)] for sets in validation_sets]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04a515c8",
   "metadata": {},
   "source": [
    "# Q2. SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "89198857",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../data/mnist_data.npz'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[44], line 25\u001b[0m\n\u001b[1;32m     22\u001b[0m     plt\u001b[38;5;241m.\u001b[39mshow()\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m# (a) MNIST dataset\u001b[39;00m\n\u001b[0;32m---> 25\u001b[0m mnist_data \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m../data/mnist_data.npz\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m X_mnist \u001b[38;5;241m=\u001b[39m mnist_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtraining_data\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     27\u001b[0m y_mnist \u001b[38;5;241m=\u001b[39m mnist_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtraining_labels\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/numpy/lib/npyio.py:405\u001b[0m, in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding, max_header_size)\u001b[0m\n\u001b[1;32m    403\u001b[0m     own_fid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    404\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 405\u001b[0m     fid \u001b[38;5;241m=\u001b[39m stack\u001b[38;5;241m.\u001b[39menter_context(\u001b[38;5;28mopen\u001b[39m(os_fspath(file), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m    406\u001b[0m     own_fid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    408\u001b[0m \u001b[38;5;66;03m# Code to distinguish from NumPy binary files and pickles.\u001b[39;00m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../data/mnist_data.npz'"
     ]
    }
   ],
   "source": [
    "def train_and_plot_svm(X_train, y_train, X_val, y_val, num_train_examples, title):\n",
    "    # Create and train the SVM model\n",
    "    svm_model = SVC(kernel='linear')\n",
    "    svm_model.fit(X_train, y_train)\n",
    "\n",
    "    # Predict on training and validation sets\n",
    "    y_train_pred = svm_model.predict(X_train)\n",
    "    y_val_pred = svm_model.predict(X_val)\n",
    "\n",
    "    # Calculate accuracy on training and validation sets\n",
    "    train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "    val_accuracy = accuracy_score(y_val, y_val_pred)\n",
    "\n",
    "    # Plot the accuracies\n",
    "    plt.plot(num_train_examples, train_accuracy, 'o-', label='Training Accuracy')\n",
    "    plt.plot(num_train_examples, val_accuracy, 'o-', label='Validation Accuracy')\n",
    "    plt.xlabel('Number of Training Examples')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.title(title + ': SVM Accuracy vs. Number of Training Examples')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "# (a) MNIST dataset\n",
    "mnist_data = np.load('../data/mnist_data.npz')\n",
    "X_mnist = mnist_data['training_data']\n",
    "y_mnist = mnist_data['training_labels']\n",
    "X_mnist_val = mnist_data['test_data'].astype(float) / 255.0  # Normalize test data as well\n",
    "\n",
    "training_examples = [100, 200, 500, 1000, 2000, 5000, 10000]\n",
    "train_and_plot_svm(X_mnist, y_mnist, X_mnist_val, y_mnist_val, training_examples, 'MNIST')\n",
    "\n",
    "# (b) Spam dataset\n",
    "spam_data = np.load('../data/spam_data.npz')\n",
    "X_spam = spam_data['training_data']\n",
    "y_spam = spam_data['training_labels']\n",
    "X_spam_val = spam_data['test_data']\n",
    "\n",
    "training_examples = [100, 200, 500, 1000, 2000, X_spam.shape[0]]\n",
    "train_and_plot_svm(X_spam, y_spam, X_spam_val, y_spam_val, training_examples, 'Spam')\n",
    "\n",
    "# (c) CIFAR-10 dataset\n",
    "cifar10_data = np.load('data/cifar10_data.npz')\n",
    "X_cifar10 = cifar10_data['training_data']\n",
    "y_cifar10 = cifar10_data['training_labels']\n",
    "X_cifar10_val = cifar10_data['test_data'].astype(float) / 255.0  # Normalize test data as well\n",
    "\n",
    "training_examples = [100, 200, 500, 1000, 2000, 5000]\n",
    "train_and_plot_svm(X_cifar10, y_cifar10, X_cifar10_val, y_cifar10_val, training_examples, 'CIFAR-10')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "541d289b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
